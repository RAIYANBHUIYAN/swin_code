{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1299795,"sourceType":"datasetVersion","datasetId":751906}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install \"protobuf==3.20.*\" --force-reinstall\n!pip install -q \"monai[nibabel]\" --no-deps\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T07:26:53.570189Z","iopub.execute_input":"2025-12-06T07:26:53.570477Z","iopub.status.idle":"2025-12-06T07:27:01.833287Z","shell.execute_reply.started":"2025-12-06T07:26:53.570454Z","shell.execute_reply":"2025-12-06T07:27:01.832551Z"}},"outputs":[{"name":"stdout","text":"Collecting protobuf==3.20.*\n  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\nDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: protobuf\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 6.33.0\n    Uninstalling protobuf-6.33.0:\n      Successfully uninstalled protobuf-6.33.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed protobuf-3.20.3\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os, random, numpy as np, nibabel as nib, time\nfrom tqdm.auto import tqdm\nfrom glob import glob\n\nimport torch, torch.nn as nn\nfrom torch.utils.data import DataLoader\n\nimport monai\nfrom monai.transforms import (\n    LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd,\n    CropForegroundd, NormalizeIntensityd, ResizeWithPadOrCropd,\n    ConcatItemsd, EnsureTyped\n)\nfrom monai.data import Dataset, CacheDataset\nfrom monai.networks.nets import SwinUNETR\nfrom monai.losses import DiceCELoss, FocalLoss, TverskyLoss\nfrom monai.inferers import sliding_window_inference\n\nprint(\"MONAI:\", monai.__version__)\nprint(\"Torch:\", torch.__version__)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Device:\", device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-06T07:27:01.834576Z","iopub.execute_input":"2025-12-06T07:27:01.834797Z"}},"outputs":[{"name":"stderr","text":"<frozen importlib._bootstrap_external>:1241: FutureWarning: The cuda.cudart module is deprecated and will be removed in a future release, please switch to use the cuda.bindings.runtime module instead.\n2025-12-06 07:27:23.126093: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765006043.292541      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765006043.346300      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"BASE = \"/kaggle/input/brats20-dataset-training-validation\"\n\nTRAIN_DIR = f\"{BASE}/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\"\nVAL_DIR   = f\"{BASE}/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData\"\nTEST_DIR  = VAL_DIR  # No labels provided, will use for inference only\n\nIMG_SIZE = (96, 96, 96)\nIN_CHANNELS = 4\nOUT_CHANNELS = 4   # 0,1,2,3 (we remap 4->3)\nBATCH_SIZE = 2\nEPOCHS = 2\nLR = 1e-4\n\nOUTDIR = \"/kaggle/working/swin_unetr_run\"\nCKPT_DIR = f\"{OUTDIR}/checkpoints\"; os.makedirs(CKPT_DIR, exist_ok=True)\nPRED_DIR = f\"{OUTDIR}/predictions\"; os.makedirs(PRED_DIR, exist_ok=True)\n\nSEED = 42\nrandom.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n\nprint(\"OUTPUT DIR:\", OUTDIR)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_brats_train(root):\n    items = []\n    for case in sorted(os.listdir(root)):\n        folder = f\"{root}/{case}\"\n\n        # Skip junk files / CSV / non-directories\n        if not os.path.isdir(folder): \n            continue\n        if case.endswith(\".csv\") or case.startswith(\".\"):\n            continue\n        \n        cid = case\n        \n        f = f\"{folder}/{cid}_flair.nii\"\n        t1 = f\"{folder}/{cid}_t1.nii\"\n        t1ce = f\"{folder}/{cid}_t1ce.nii\"\n        t2 = f\"{folder}/{cid}_t2.nii\"\n        seg = f\"{folder}/{cid}_seg.nii\"\n\n        # Make sure ALL 4 modalities + seg exist\n        if os.path.exists(f) and os.path.exists(t1) and os.path.exists(t1ce) and os.path.exists(t2) and os.path.exists(seg):\n            items.append({\"id\": cid, \"flair\": f, \"t1\": t1, \"t1ce\": t1ce, \"t2\": t2, \"seg\": seg})\n    \n    return items\n\n\ndef load_brats_test(root):\n    items = []\n    for case in sorted(os.listdir(root)):\n        folder = f\"{root}/{case}\"\n        if not os.path.isdir(folder): \n            continue\n        if case.endswith(\".csv\") or case.startswith(\".\"):\n            continue\n\n        cid = case\n        f = f\"{folder}/{cid}_flair.nii\"\n        t1 = f\"{folder}/{cid}_t1.nii\"\n        t1ce = f\"{folder}/{cid}_t1ce.nii\"\n        t2 = f\"{folder}/{cid}_t2.nii\"\n\n        if os.path.exists(f) and os.path.exists(t1) and os.path.exists(t1ce) and os.path.exists(t2):\n            items.append({\"id\": cid, \"flair\": f, \"t1\": t1, \"t1ce\": t1ce, \"t2\": t2})\n    return items\n\n\ntrain_files = load_brats_train(TRAIN_DIR)\ntest_files  = load_brats_test(TEST_DIR)\n\nprint(\"Train cases:\", len(train_files))\nprint(\"Test cases:\", len(test_files))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_transforms = monai.transforms.Compose([\n    LoadImaged(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\",\"seg\"]),\n    EnsureChannelFirstd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\",\"seg\"]),\n    Orientationd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\",\"seg\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\",\"seg\"],\n             pixdim=(1,1,1), mode=(\"bilinear\",\"bilinear\",\"bilinear\",\"bilinear\",\"nearest\")),\n    CropForegroundd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\",\"seg\"], source_key=\"flair\"),\n    ResizeWithPadOrCropd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\",\"seg\"], spatial_size=IMG_SIZE),\n    NormalizeIntensityd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\"], nonzero=True, channel_wise=True),\n    ConcatItemsd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\"], name=\"image\"),\n    EnsureTyped(keys=[\"image\",\"seg\"])\n])\n\ntest_transforms = monai.transforms.Compose([\n    LoadImaged(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\"]),\n    EnsureChannelFirstd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\"]),\n    Orientationd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\"], axcodes=\"RAS\"),\n    Spacingd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\"], pixdim=(1,1,1),\n             mode=(\"bilinear\",\"bilinear\",\"bilinear\",\"bilinear\")),\n    CropForegroundd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\"], source_key=\"flair\"),\n    ResizeWithPadOrCropd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\"], spatial_size=IMG_SIZE),\n    NormalizeIntensityd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\"], nonzero=True, channel_wise=True),\n    ConcatItemsd(keys=[\"flair\",\"t1\",\"t1ce\",\"t2\"], name=\"image\"),\n    EnsureTyped(keys=[\"image\"])\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_ds = CacheDataset(train_files, transform=train_transforms, cache_rate=0.7)\ntest_ds  = Dataset(test_files, transform=test_transforms)\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\nval_loader   = DataLoader(train_ds, batch_size=1, shuffle=False)  # since training has labels\ntest_loader  = DataLoader(test_ds, batch_size=1, shuffle=False)\n\nprint(\"Batches => Train:\", len(train_loader), \"Val:\", len(val_loader), \"Test:\", len(test_loader))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = SwinUNETR(\n       \n    in_channels=4,\n    out_channels=4,\n    feature_size=48,\n    use_checkpoint=True\n).to(device)\n\n\nloss_dicece = DiceCELoss(include_background=False, to_onehot_y=True, softmax=True)\nloss_tversky = TverskyLoss(alpha=0.3, beta=0.7, to_onehot_y=True, softmax=True)\nloss_focal = FocalLoss(include_background=False, to_onehot_y=True, gamma=2.0)\n\ndef hybrid_loss(pred, target):\n    target[target == 4] = 3\n    l1 = loss_dicece(pred, target)\n    l2 = loss_tversky(pred, target)\n    l3 = loss_focal(pred, target)\n    return 0.4*l1 + 0.3*l2 + 0.3*l3\n\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-5)\nscaler = torch.cuda.amp.GradScaler()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def dice_region(pred, gt):\n    pred = pred.cpu().numpy()[0]\n    gt   = gt.cpu().numpy()[0]\n    gt[gt==4] = 3\n\n    eps = 1e-7\n    scores = {}\n    scores[\"WT\"] = (2*np.sum((pred>0)&(gt>0))) / (np.sum(pred>0)+np.sum(gt>0)+eps)\n    scores[\"TC\"] = (2*np.sum(((pred==1)|(pred==3)) & ((gt==1)|(gt==3)))) / (\n                   np.sum((pred==1)|(pred==3))+np.sum((gt==1)|(gt==3))+eps)\n    scores[\"ET\"] = (2*np.sum((pred==3)&(gt==3))) / (np.sum(pred==3)+np.sum(gt==3)+eps)\n    return scores\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"best_dice = 0\nper_class_dice_history = []   \ntrain_losses = []             \n\nfor epoch in range(1, EPOCHS+1):\n    model.train()\n    running_loss = 0\n\n    # ================== TRAIN ==================\n    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\")\n    for batch in pbar:\n        img = batch[\"image\"].to(device)\n        seg = batch[\"seg\"].to(device)\n\n        optimizer.zero_grad()\n        with torch.amp.autocast('cuda'):\n            pred = model(img)\n            loss = hybrid_loss(pred, seg)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        running_loss += loss.item()\n        pbar.set_postfix({\"loss\": f\"{running_loss/(pbar.n+1):.4f}\"})\n\n    # ================== VALIDATION ==================\n    model.eval()\n    dices = {\"WT\":[], \"TC\":[], \"ET\":[]}\n\n    with torch.no_grad():\n        vbar = tqdm(val_loader, desc=\"Validating\", leave=False)\n        for v in vbar:\n            img = v[\"image\"].to(device)\n            seg = v[\"seg\"].to(device)\n\n            out = sliding_window_inference(img, IMG_SIZE, 1, model)\n            pred = torch.argmax(out.softmax(1), 1, keepdim=True)\n            d = dice_region(pred, seg)\n            for k in d: dices[k].append(d[k])\n\n    mean_dice = np.mean([np.mean(v) for v in dices.values()])\n    print(f\"ğŸ¯ Dice -> WT:{np.mean(dices['WT']):.4f}, TC:{np.mean(dices['TC']):.4f}, ET:{np.mean(dices['ET']):.4f}, Mean:{mean_dice:.4f}\")\n\n    # ---- Save epoch metrics ----\n    per_class_dice_history.append([\n        np.mean(dices[\"WT\"]),\n        np.mean(dices[\"TC\"]),\n        np.mean(dices[\"ET\"])\n    ])\n    train_losses.append(running_loss/(len(train_loader)))\n\n    if mean_dice > best_dice:\n        best_dice = mean_dice\n        torch.save(model.state_dict(), f\"{CKPT_DIR}/best_swin_hybrid.pth\")\n        print(\"ğŸ’¾ Saved best model!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.load_state_dict(torch.load(f\"{CKPT_DIR}/best_swin_hybrid.pth\", map_location=device))\nmodel.eval()\n\nfor batch in tqdm(test_loader, desc=\"Inference\"):\n    pid = batch[\"id\"][0]\n    img = batch[\"image\"].to(device)\n\n    out = sliding_window_inference(img, IMG_SIZE, 1, model)\n    pred = torch.argmax(out.softmax(1), 1).cpu().numpy()[0]\n\n    affine = np.eye(4)\n    for key in [\"flair\",\"t1\",\"t1ce\",\"t2\"]:\n        if key in batch and hasattr(batch[key][0], \"meta\"):\n            try:\n                affine = nib.load(batch[key][0].meta[\"filename_or_obj\"]).affine\n                break\n            except: pass\n\n    nib.save(nib.Nifti1Image(pred.astype(np.uint8), affine),\n             f\"{PRED_DIR}/{pid}_pred.nii.gz\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================== SAVE RESULTS =====================\nimport pandas as pd\n\ndf = pd.DataFrame(per_class_dice_history, columns=[\"WT\",\"TC\",\"ET\"])\ndf[\"Mean\"] = df.mean(axis=1)\ndf[\"Train_Loss\"] = train_losses\ndf.to_csv(f\"{OUTDIR}/metrics_log.csv\", index_label=\"Epoch\")\n\nprint(\"\\nğŸ“Œ Metrics saved at:\", f\"{OUTDIR}/metrics_log.csv\")\n\n# ===================== PLOT DICE CURVES =====================\nplt.figure(figsize=(10,5))\nplt.plot(df[\"WT\"], label=\"WT\")\nplt.plot(df[\"TC\"], label=\"TC\")\nplt.plot(df[\"ET\"], label=\"ET\")\nplt.plot(df[\"Mean\"], label=\"Mean\", linewidth=3, color=\"black\")\nplt.title(\"Dice Score Progress\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Dice\")\nplt.legend()\nplt.grid()\nplt.savefig(f\"{OUTDIR}/dice_curve.png\", dpi=200)\nplt.show()\n\n# ===================== PLOT LOSS =====================\nplt.figure(figsize=(6,4))\nplt.plot(df[\"Train_Loss\"], marker=\"o\")\nplt.title(\"Training Loss Curve\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.grid()\nplt.savefig(f\"{OUTDIR}/loss_curve.png\", dpi=200)\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}